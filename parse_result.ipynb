{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier: DGCNN, method: tent\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n",
      "classifier: DGCNN, method: lame\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n",
      "classifier: DGCNN, method: sar\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n",
      "classifier: DGCNN, method: pl\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n",
      "classifier: DGCNN, method: memo\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n",
      "classifier: DGCNN, method: dua\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n",
      "classifier: DGCNN, method: bn_stats\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n",
      "classifier: DGCNN, method: shot\n",
      "unadapted_result_list: [-1.0]\n",
      "total_result_list: [-1.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_avg_online_acc(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_acc = before_adaptation_match[-1]\n",
    "            after_adaptation_test_acc = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_acc': before_adaptation_test_acc,\n",
    "                'after_adaptation_acc': after_adaptation_test_acc,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_acc': -1,\n",
    "                'after_adaptation_acc': -1,\n",
    "            }\n",
    "    else:\n",
    "        return {\n",
    "            'before_adaptation_acc': -1,\n",
    "            'after_adaptation_acc': -1,\n",
    "        }\n",
    "\n",
    "        # raise NotImplementedError\n",
    "        # return -1\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_avg_online_acc(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_acc = before_adaptation_match[-1]\n",
    "            after_adaptation_test_acc = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_acc': before_adaptation_test_acc,\n",
    "                'after_adaptation_acc': after_adaptation_test_acc,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_acc': -1,\n",
    "                'after_adaptation_acc': -1,\n",
    "            }\n",
    "    else:\n",
    "        # raise NotImplementedError\n",
    "        return {\n",
    "            'before_adaptation_acc': -1,\n",
    "            'after_adaptation_acc': -1,\n",
    "        }\n",
    "\n",
    "\n",
    "def get_avg_online_recall(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| macro recall: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| macro recall: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_macro_recall = before_adaptation_match[-1]\n",
    "            after_adaptation_test_macro_recall = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_macro_recall': before_adaptation_test_macro_recall,\n",
    "                'after_adaptation_macro_recall': after_adaptation_test_macro_recall,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_macro_recall': -1,\n",
    "                'after_adaptation_macro_recall': -1,\n",
    "            }\n",
    "    else:\n",
    "        # raise NotImplementedError\n",
    "        return {\n",
    "            'before_adaptation_macro_recall': -1,\n",
    "            'after_adaptation_macro_recall': -1,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "# # parse tent result\n",
    "# classifier_list = [\"DGCNN\"]\n",
    "# method_list = [\"tent\"]\n",
    "# random_seed_list = [2]\n",
    "# corruption_list = [\"background\", \"cutout\", \"density\", \"density_inc\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\", \"gaussian\", \"impulse\", \"lidar\", \"occlusion\", \"rotation\", \"shear\", \"uniform\", \"upsampling\"]\n",
    "# severity_list = [5]\n",
    "\n",
    "# for method in method_list:\n",
    "#     unadapted_result_list = []\n",
    "#     total_result_list = []\n",
    "#     for classifier in classifier_list:\n",
    "#         for corruption in corruption_list:\n",
    "#             for severity in severity_list: # one result\n",
    "#                 result_list = []\n",
    "#                 for random_seed in random_seed_list:\n",
    "#                     try:\n",
    "#                         log_dir = f\"exps/_{classifier}_{corruption}_{severity}_{random_seed}_{method}/run.log\"\n",
    "#                         result = get_avg_online_acc(log_dir)\n",
    "#                     except:\n",
    "#                         log_dir = f\"exps/modelnet40c_{corruption}_{severity}_{classifier}_{corruption}_{severity}_{random_seed}_{method}/run.log\"\n",
    "#                         result = get_avg_online_acc(log_dir)\n",
    "#                     # print(f\"classifier: {classifier}, method: {method}, corruption: {corruption}, severity: {severity}, random_seed: {random_seed}\")\n",
    "#                     # print(f\"result: {result}\\n\")\n",
    "#                 unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "#                 total_result_list.append(float(result['after_adaptation_acc']))\n",
    "#     print(f\"unadapted_result_list: {unadapted_result_list}\")\n",
    "#     print(f\"total_result_list: {total_result_list}\")\n",
    "\n",
    "\n",
    "# parse lame result\n",
    "# classifier_list = [\"DGCNN\"]\n",
    "# method_list = [\"lame\"]\n",
    "# random_seed_list = [2]\n",
    "# corruption_list = [\"background\", \"cutout\", \"density\", \"density_inc\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\", \"gaussian\", \"impulse\", \"lidar\", \"occlusion\", \"rotation\", \"shear\", \"uniform\", \"upsampling\"]\n",
    "# severity_list = [5]\n",
    "\n",
    "# for method in method_list:\n",
    "#     unadapted_result_list = []\n",
    "#     total_result_list = []\n",
    "#     for classifier in classifier_list:\n",
    "#         for corruption in corruption_list:\n",
    "#             for severity in severity_list: # one result\n",
    "#                 result_list = []\n",
    "#                 for random_seed in random_seed_list:\n",
    "#                     log_dir = f\"exps/modelnet40c_{corruption}_{severity}_{classifier}_{corruption}_{severity}_{random_seed}_{method}/run.log\"\n",
    "#                     result = get_avg_online_acc(log_dir)\n",
    "#                     print(f\"classifier: {classifier}, method: {method}, corruption: {corruption}, severity: {severity}, random_seed: {random_seed}\")\n",
    "#                     print(f\"result: {result}\\n\")\n",
    "#                 unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "#                 total_result_list.append(float(result['after_adaptation_acc']))\n",
    "#     print(f\"unadapted_result_list: {unadapted_result_list}\")\n",
    "#     print(f\"total_result_list: {total_result_list}\")\n",
    "\n",
    "\n",
    "classifier_list = [\"DGCNN\"]\n",
    "method_list = [\"tent\", \"lame\", \"sar\", \"pl\", \"memo\", \"dua\", \"bn_stats\", \"shot\"]\n",
    "# method_list = [\"tent\", \"lame\", \"pl\", \"shot\"]\n",
    "# method_list = [\"tent\", \"lame\", \"sar\", \"pl\", \"memo\", \"dua\", \"bn_stats\", \"shot\", \"dda\"]\n",
    "random_seed_list = [2]\n",
    "# corruption_list = [\"background\", \"cutout\", \"density\", \"density_inc\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\", \"gaussian\", \"impulse\", \"lidar\", \"occlusion\", \"rotation\", \"shear\", \"uniform\", \"upsampling\"]\n",
    "# corruption_list = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]\n",
    "corruption_list = [\"density\"]\n",
    "severity_list = [5]\n",
    "seed=2\n",
    "for method in method_list:\n",
    "    unadapted_result_list = []\n",
    "    total_result_list = []\n",
    "    for classifier in classifier_list:\n",
    "        for corruption in corruption_list:\n",
    "            for severity in severity_list: # one result\n",
    "                result_list = []\n",
    "                for random_seed in random_seed_list:\n",
    "                    log_dir = f\"exps/eval_{classifier}_modelnet40c_{corruption}_{severity}_{method}_{seed}/run.log\"\n",
    "                    result = get_avg_online_acc(log_dir)\n",
    "                    # print(f\"classifier: {classifier}, method: {method}, corruption: {corruption}, severity: {severity}, random_seed: {random_seed}\")\n",
    "                unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "                total_result_list.append(float(result['after_adaptation_acc']))\n",
    "        print(f\"classifier: {classifier}, method: {method}\")\n",
    "        print(f\"unadapted_result_list: {unadapted_result_list}\")\n",
    "        print(f\"total_result_list: {total_result_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier: DGCNN, method: tent, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: tent, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n",
      "classifier: DGCNN, method: lame, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: lame, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n",
      "classifier: DGCNN, method: sar, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: sar, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n",
      "classifier: DGCNN, method: pl, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: pl, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n",
      "classifier: DGCNN, method: memo, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: memo, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n",
      "classifier: DGCNN, method: dua, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: dua, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n",
      "classifier: DGCNN, method: bn_stats, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: bn_stats, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n",
      "classifier: DGCNN, method: shot, corruption: background, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: cutout, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: density, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: density_inc, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: distortion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: distortion_rbf, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: distortion_rbf_inv, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: gaussian, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: impulse, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: lidar, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: occlusion, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: rotation, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: shear, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: uniform, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "classifier: DGCNN, method: shot, corruption: upsampling, severity: 5, random_seed: 2\n",
      "result: {'before_adaptation_acc': -1, 'after_adaptation_acc': -1}\n",
      "\n",
      "unadapted_result_list: []\n",
      "total_result_list: []\n"
     ]
    }
   ],
   "source": [
    "# # parse tent result\n",
    "# classifier_list = [\"DGCNN\"]\n",
    "# method_list = [\"tent\"]\n",
    "# random_seed_list = [2]\n",
    "# corruption_list = [\"background\", \"cutout\", \"density\", \"density_inc\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\", \"gaussian\", \"impulse\", \"lidar\", \"occlusion\", \"rotation\", \"shear\", \"uniform\", \"upsampling\"]\n",
    "# severity_list = [5]\n",
    "\n",
    "# for method in method_list:\n",
    "#     unadapted_result_list = []\n",
    "#     total_result_list = []\n",
    "#     for classifier in classifier_list:\n",
    "#         for corruption in corruption_list:\n",
    "#             for severity in severity_list: # one result\n",
    "#                 result_list = []\n",
    "#                 for random_seed in random_seed_list:\n",
    "#                     try:\n",
    "#                         log_dir = f\"exps/_{classifier}_{corruption}_{severity}_{random_seed}_{method}/run.log\"\n",
    "#                         result = get_avg_online_acc(log_dir)\n",
    "#                     except:\n",
    "#                         log_dir = f\"exps/modelnet40c_{corruption}_{severity}_{classifier}_{corruption}_{severity}_{random_seed}_{method}/run.log\"\n",
    "#                         result = get_avg_online_acc(log_dir)\n",
    "#                     # print(f\"classifier: {classifier}, method: {method}, corruption: {corruption}, severity: {severity}, random_seed: {random_seed}\")\n",
    "#                     # print(f\"result: {result}\\n\")\n",
    "#                 unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "#                 total_result_list.append(float(result['after_adaptation_acc']))\n",
    "#     print(f\"unadapted_result_list: {unadapted_result_list}\")\n",
    "#     print(f\"total_result_list: {total_result_list}\")\n",
    "\n",
    "\n",
    "# parse lame result\n",
    "classifier_list = [\"DGCNN\"]\n",
    "# method_list = [\"lame\"]\n",
    "METHOD_LIST = [\"tent\", \"lame\", \"sar\", \"pl\", \"memo\", \"dua\", \"bn_stats\", \"shot\"]\n",
    "random_seed_list = [2]\n",
    "corruption_list = [\"background\", \"cutout\", \"density\", \"density_inc\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\", \"gaussian\", \"impulse\", \"lidar\", \"occlusion\", \"rotation\", \"shear\", \"uniform\", \"upsampling\"]\n",
    "severity_list = [5]\n",
    "\n",
    "for method in METHOD_LIST:\n",
    "    unadapted_result_list = []\n",
    "    total_result_list = []\n",
    "    for classifier in classifier_list:\n",
    "        for corruption in corruption_list:\n",
    "            for severity in severity_list: # one result\n",
    "                result_list = []\n",
    "                for random_seed in random_seed_list:\n",
    "                    log_dir = f\"exps/modelnet40c_{corruption}_{severity}_{classifier}_{corruption}_{severity}_{random_seed}_{method}/run.log\"\n",
    "                    result = get_avg_online_acc(log_dir)\n",
    "                    print(f\"classifier: {classifier}, method: {method}, corruption: {corruption}, severity: {severity}, random_seed: {random_seed}\")\n",
    "                    print(f\"result: {result}\\n\")\n",
    "                # unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "                # total_result_list.append(float(result['after_adaptation_acc']))\n",
    "    print(f\"unadapted_result_list: {unadapted_result_list}\")\n",
    "    print(f\"total_result_list: {total_result_list}\")\n",
    "\n",
    "\n",
    "# classifier_list = [\"DGCNN\"]\n",
    "# METHOD_LIST = [\"tent\", \"lame\", \"sar\", \"pl\", \"memo\", \"dua\", \"bn_stats\", \"shot\"]\n",
    "# # method_list = [\"tent\", \"lame\", \"pl\", \"shot\"]\n",
    "# # method_list = [\"tent\", \"lame\", \"sar\", \"pl\", \"memo\", \"dua\", \"bn_stats\", \"shot\", \"dda\"]\n",
    "# random_seed_list = [2]\n",
    "# # corruption_list = [\"background\", \"cutout\", \"density\", \"density_inc\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\", \"gaussian\", \"impulse\", \"lidar\", \"occlusion\", \"rotation\", \"shear\", \"uniform\", \"upsampling\"]\n",
    "# # corruption_list = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]\n",
    "# corruption_list = [\"density\"]\n",
    "# severity_list = [5]\n",
    "# RANDOM_SEED_LIST = [2]\n",
    "# BATCH_SIZE_LIST = [1, 16, 64]\n",
    "# SOURCE_DOMAIN_LIST = [\"modelnet\", \"modelnet\", \"shapenet\", \"shapenet\", \"scannet\", \"scannet\"]\n",
    "# TARGET_DOMAIN_LIST = [\"shapenet\", \"scannet\", \"modelnet\", \"scannet\", \"modelnet\", \"shapenet\"]\n",
    "\n",
    "\n",
    "# for batch_size in BATCH_SIZE_LIST:\n",
    "#     for classifier in classifier_list:\n",
    "#         for source, target in zip(SOURCE_DOMAIN_LIST, TARGET_DOMAIN_LIST):\n",
    "#             for method in METHOD_LIST:\n",
    "#                 result_list = []\n",
    "#                 for random_seed in RANDOM_SEED_LIST:\n",
    "#                     log_dir = f\"exps/eval_classifier_{classifier}_source_{source}_target_{target}_method_{method}_seed_{random_seed}_batch_size_{batch_size}/run.log\"\n",
    "#                     result = get_avg_online_acc(log_dir)\n",
    "#                     print(f\"batch_size, classifier, source, target, method, random_seed: {batch_size}, {classifier}, {source}, {target}, {method}, {random_seed}\")\n",
    "#                     print(f\"result: {result}\")\n",
    "\n",
    "\n",
    "# for method in method_list:\n",
    "#     unadapted_result_list = []\n",
    "#     total_result_list = []\n",
    "#     for classifier in classifier_list:\n",
    "#         for corruption in corruption_list:\n",
    "#             for severity in severity_list: # one result\n",
    "#                 result_list = []\n",
    "#                 for random_seed in random_seed_list:\n",
    "#                     log_dir = f\"exps/eval_{classifier}_modelnet40c_{corruption}_{severity}_{method}_{seed}/run.log\"\n",
    "#                     result = get_avg_online_acc(log_dir)\n",
    "#                     # print(f\"classifier: {classifier}, method: {method}, corruption: {corruption}, severity: {severity}, random_seed: {random_seed}\")\n",
    "#                 unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "#                 total_result_list.append(float(result['after_adaptation_acc']))\n",
    "#         print(f\"classifier: {classifier}, method: {method}\")\n",
    "#         print(f\"unadapted_result_list: {unadapted_result_list}\")\n",
    "#         print(f\"total_result_list: {total_result_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_avg_online_acc(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_acc = before_adaptation_match[-1]\n",
    "            after_adaptation_test_acc = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_acc': before_adaptation_test_acc,\n",
    "                'after_adaptation_acc': after_adaptation_test_acc,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_acc': -1,\n",
    "                'after_adaptation_acc': -1,\n",
    "            }\n",
    "    else:\n",
    "        # raise NotImplementedError\n",
    "        return {\n",
    "            'before_adaptation_acc': -1,\n",
    "            'after_adaptation_acc': -1,\n",
    "        }\n",
    "\n",
    "\n",
    "def get_avg_online_recall(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| macro recall: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| macro recall: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_macro_recall = before_adaptation_match[-1]\n",
    "            after_adaptation_test_macro_recall = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_macro_recall': before_adaptation_test_macro_recall,\n",
    "                'after_adaptation_macro_recall': after_adaptation_test_macro_recall,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_macro_recall': -1,\n",
    "                'after_adaptation_macro_recall': -1,\n",
    "            }\n",
    "    else:\n",
    "        # raise NotImplementedError\n",
    "        return {\n",
    "            'before_adaptation_macro_recall': -1,\n",
    "            'after_adaptation_macro_recall': -1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: bn_stats, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.8456]\n",
      "\n",
      "unadapted_list: [0.8144]\n",
      "method: dua, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.8456]\n",
      "\n",
      "unadapted_list: [0.8144]\n"
     ]
    }
   ],
   "source": [
    "# main table for modelnet40c\n",
    "\n",
    "# parse lame result\n",
    "random_seed_list = [2]\n",
    "classifier_list = [\"DGCNN\"]\n",
    "# METHOD_LIST = [\"pl\", \"tent\", \"shot\", \"memo\", \"sar\", \"bn_stats\", \"dua\", \"lame\", \"dda\"]\n",
    "METHOD_LIST = [\"bn_stats\", \"dua\"]\n",
    "# corruption_list = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]\n",
    "corruption_list = [\"upsampling\"]\n",
    "severity_list = [5]\n",
    "\n",
    "# batch_size_list = [64, 8, 1]\n",
    "batch_size_list = [64]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        unadapted_result_list = []\n",
    "        total_result_list = []\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_list = []\n",
    "            result_list = []\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}/run.log\"\n",
    "                        # print(log_dir, os.path.exists(log_dir))\n",
    "\n",
    "                        result = get_avg_online_acc(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_acc']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"result: {result_list}\\n\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: dda, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [0.6617, 0.1803, 0.7839, 0.3488, 0.6343, 0.4153]\n",
      "unadapted_list: [0.8138, 0.5285, 0.7769, 0.4483, 0.6145, 0.6469]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main table for pointda\n",
    "\n",
    "# parse lame result\n",
    "random_seed_list = [2]\n",
    "classifier_list = [\"DGCNN\"]\n",
    "# METHOD_LIST = [\"pl\", \"tent\", \"shot\", \"memo\", \"sar\", \"bn_stats\", \"dua\", \"lame\", \"dda\"]\n",
    "METHOD_LIST = [\"dda\"]\n",
    "source_list = [\"modelnet\", \"modelnet\", \"shapenet\", \"shapenet\", \"scannet\", \"scannet\"]\n",
    "target_list = [\"shapenet\", \"scannet\", 'modelnet', \"scannet\", \"modelnet\", \"shapenet\"]\n",
    "\n",
    "# batch_size_list = [64, 8, 1]\n",
    "batch_size_list = [32]\n",
    "\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        total_result_list = []\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "            for source, target in zip(source_list, target_list):\n",
    "                for random_seed in random_seed_list:\n",
    "                    log_dir = f\"exps/eval_classifier_{classifier}_source_{source}_target_{target}_method_{method}_seed_{random_seed}_batch_size_{batch_size}/run.log\"\n",
    "                    result = get_avg_online_acc(log_dir)\n",
    "                    result_list.append(float(result['after_adaptation_acc']))\n",
    "                    unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"result: {result_list}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: pl, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: tent, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: shot, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: memo, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: sar, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: bn_stats, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: dua, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: lame, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "method: dda, batch_size: 16, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main table for graspnet\n",
    "\n",
    "# parse lame result\n",
    "classifier_list = [\"DGCNN\"]\n",
    "# method_list = [\"lame\"]\n",
    "METHOD_LIST = [\"pl\", \"tent\", \"shot\", \"memo\", \"sar\", \"bn_stats\", \"dua\", \"lame\", \"dda\"]\n",
    "random_seed_list = [2]\n",
    "\n",
    "source_list = [\"synthetic\", \"synthetic\", \"kinect\", \"realsense\"]\n",
    "target_list = [\"kinect\", \"realsense\", \"realsense\", \"kinect\"]\n",
    "# batch_size_list = [64, 8, 1]\n",
    "batch_size_list = [16]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "            for source, target in zip(source_list, target_list):\n",
    "                for random_seed in random_seed_list:\n",
    "                    log_dir = f\"exps/eval_classifier_{classifier}_source_{source}_target_{target}_method_{method}_seed_{random_seed}_batch_size_{batch_size}/run.log\"\n",
    "                    result = get_avg_online_acc(log_dir)\n",
    "                    result_list.append(float(result['after_adaptation_acc']))\n",
    "                    unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"result: {result_list}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path.exists(log_dir): True\n",
      "method: dda, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [0.797]\n",
      "unadapted_list: [0.7767]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main table for mixed distribution shift\n",
    "\n",
    "# parse lame result\n",
    "classifier_list = [\"DGCNN\"]\n",
    "# method_list = [\"lame\"]\n",
    "# METHOD_LIST = [\"pl\", \"tent\", \"shot\", \"memo\", \"sar\", \"bn_stats\", \"dua\", \"lame\", \"dda\"]\n",
    "METHOD_LIST = [\"dda\"]\n",
    "random_seed_list = [2]\n",
    "\n",
    "batch_size_list = [16]\n",
    "\n",
    "corruption_list = [\"background\"]\n",
    "severity_list = [5]\n",
    "\n",
    "# batch_size_list = [64, 8, 1]\n",
    "batch_size_list = [32]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            result_list = []\n",
    "            unadapted_result_list = []\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_scenario_mixed/run.log\"\n",
    "                        print(f\"os.path.exists(log_dir): {os.path.exists(log_dir)}\")\n",
    "                        result = get_avg_online_acc(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_acc']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"result: {result_list}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: pl, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.1021]\n",
      "unadapted_list: [0.8144]\n",
      "\n",
      "method: tent, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.111]\n",
      "unadapted_list: [0.8144]\n",
      "\n",
      "method: shot, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.2188]\n",
      "unadapted_list: [0.8144]\n",
      "\n",
      "method: memo, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0]\n",
      "unadapted_list: [-1.0]\n",
      "\n",
      "method: sar, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.1187]\n",
      "unadapted_list: [0.8144]\n",
      "\n",
      "method: bn_stats, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.1276]\n",
      "unadapted_list: [0.8144]\n",
      "\n",
      "method: dua, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.1276]\n",
      "unadapted_list: [0.8144]\n",
      "\n",
      "method: lame, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [0.8335]\n",
      "unadapted_list: [0.8144]\n",
      "\n",
      "method: dda, batch_size: 64, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0]\n",
      "unadapted_list: [-1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main table for temporally correlated\n",
    "\n",
    "# parse lame result\n",
    "classifier_list = [\"DGCNN\"]\n",
    "METHOD_LIST = [\"pl\", \"tent\", \"shot\", \"memo\", \"sar\", \"bn_stats\", \"dua\", \"lame\", \"dda\"]\n",
    "random_seed_list = [2]\n",
    "# corruption_list = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]\n",
    "corruption_list = [\"upsampling\"]\n",
    "severity_list = [5]\n",
    "# batch_size_list = [64, 8, 1]\n",
    "batch_size_list = [64]\n",
    "# batch_size_list = [1]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        total_result_list = []\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_scenario_temporally_correlated/run.log\"\n",
    "                        result = get_avg_online_acc(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_acc']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "                    # unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "                    # total_result_list.append(float(result['after_adaptation_acc']))\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"result: {result_list}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'after_adaptation_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_464100/3588339468.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0;31m# log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}/run.log\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_avg_online_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                         \u001b[0mresult_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'after_adaptation_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                         \u001b[0munadapted_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'before_adaptation_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"corruption_list: {corruption_list}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'after_adaptation_acc'"
     ]
    }
   ],
   "source": [
    "# class imbalance ratio (label distribution shift)\n",
    "\n",
    "# parse lame result\n",
    "classifier_list = [\"DGCNN\"]\n",
    "# method_list = [\"lame\"]\n",
    "# METHOD_LIST = [\"pl\", \"tent\", \"shot\", \"memo\", \"sar\", \"bn_stats\", \"dua\", \"lame\", \"dda\"]\n",
    "METHOD_LIST = [\"dda\"]\n",
    "random_seed_list = [2]\n",
    "\n",
    "corruption_list = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]\n",
    "severity_list = [5]\n",
    "\n",
    "# batch_size_list = [64, 8, 1]\n",
    "batch_size_list = [32]\n",
    "\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_scenario_label_distribution_shift_imb_ratio_10/run.log\"\n",
    "                        # log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}/run.log\"\n",
    "                        result = get_avg_online_recall(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_acc']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_acc']))\n",
    "            print(f\"corruption_list: {corruption_list}\")\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"result: {result_list}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: pl, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: tent, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: shot, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: memo, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: sar, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: bn_stats, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: dua, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: lame, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: dda, batch_size: 32, classifier: DGCNN random_seed: 2\n",
      "result: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "unadapted_list: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class imbalance ratio (label distribution shift)\n",
    "\n",
    "# parse lame result\n",
    "classifier_list = [\"DGCNN\"]\n",
    "METHOD_LIST = [\"pl\", \"tent\", \"shot\", \"memo\", \"sar\", \"bn_stats\", \"dua\", \"lame\", \"dda\"]\n",
    "random_seed_list = [2]\n",
    "\n",
    "corruption_list = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]\n",
    "severity_list = [5]\n",
    "\n",
    "batch_size_list = [32]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_scenario_label_distribution_shift_imb_ratio_10_new/run.log\"\n",
    "                        result = get_avg_online_recall(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_macro_recall']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_macro_recall']))\n",
    "            print(f\"corruption_list: {corruption_list}\")\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"result: {result_list}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_avg_online_acc(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_acc = before_adaptation_match[-1]\n",
    "            after_adaptation_test_acc = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_acc': before_adaptation_test_acc,\n",
    "                'after_adaptation_acc': after_adaptation_test_acc,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_acc': -1,\n",
    "                'after_adaptation_acc': -1,\n",
    "            }\n",
    "    else:\n",
    "        return {\n",
    "            'before_adaptation_acc': -1,\n",
    "            'after_adaptation_acc': -1,\n",
    "        }\n",
    "\n",
    "        # raise NotImplementedError\n",
    "        # return -1\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_avg_online_acc(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| acc: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_acc = before_adaptation_match[-1]\n",
    "            after_adaptation_test_acc = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_acc': before_adaptation_test_acc,\n",
    "                'after_adaptation_acc': after_adaptation_test_acc,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_acc': -1,\n",
    "                'after_adaptation_acc': -1,\n",
    "            }\n",
    "    else:\n",
    "        # raise NotImplementedError\n",
    "        return {\n",
    "            'before_adaptation_acc': -1,\n",
    "            'after_adaptation_acc': -1,\n",
    "        }\n",
    "\n",
    "\n",
    "def get_avg_online_recall(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Define the regex patterns\n",
    "        before_adaptation_pattern = r'final metrics before adaptation \\| macro recall: (\\d+\\.\\d+)'\n",
    "        after_adaptation_pattern = r'final metrics after adaptation \\| macro recall: (\\d+\\.\\d+)'\n",
    "\n",
    "        # Perform the regex search on the entire file content\n",
    "        before_adaptation_match = re.findall(before_adaptation_pattern, content)\n",
    "        after_adaptation_match = re.findall(after_adaptation_pattern, content)\n",
    "\n",
    "        if before_adaptation_match and after_adaptation_match:\n",
    "            before_adaptation_test_macro_recall = before_adaptation_match[-1]\n",
    "            after_adaptation_test_macro_recall = after_adaptation_match[-1]\n",
    "            return {\n",
    "                'before_adaptation_macro_recall': before_adaptation_test_macro_recall,\n",
    "                'after_adaptation_macro_recall': after_adaptation_test_macro_recall,\n",
    "            }\n",
    "        else:\n",
    "            # raise NotImplementedError\n",
    "            return {\n",
    "                'before_adaptation_macro_recall': -1,\n",
    "                'after_adaptation_macro_recall': -1,\n",
    "            }\n",
    "    else:\n",
    "        # raise NotImplementedError\n",
    "        return {\n",
    "            'before_adaptation_macro_recall': -1,\n",
    "            'after_adaptation_macro_recall': -1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: cloudfixer, batch_size: 128, classifier: point2vec random_seed: 2\n",
      "unadapted_list: [0.4544, 0.213, 0.8568, 0.823, 0.6919, 0.5517, 0.4496, 0.5625, 0.348, 0.2963, 0.4678, 0.756, 0.7185, 0.7253, 0.7354]\n",
      "result: [0.447, 0.4218, 0.8684, 0.7997, 0.7952, 0.8719, 0.8629, 0.7821, 0.8078, 0.3807, 0.7665, 0.7586, 0.7519, 0.7866, 0.813]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: cloudfixer, batch_size: 128, classifier: point2vec random_seed: 2\n",
      "unadapted_list: [0.4526, 0.2087, 0.86, 0.8196, 0.7003, 0.5615, 0.4352, 0.5535, -1.0, 0.2854, 0.4605, 0.7517, 0.7196, 0.7223, 0.7332]\n",
      "result: [0.4437, 0.4121, 0.8432, 0.7652, 0.7879, 0.8782, 0.8772, 0.8905, -1.0, 0.6795, 0.7589, 0.761, 0.7496, 0.7774, 0.797]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: cloudfixer, batch_size: 128, classifier: point2vec random_seed: 2\n",
      "unadapted_list: [0.4522, 0.204, 0.8596, 0.819, 0.6949, 0.5582, 0.4388, 0.554, -1.0, 0.2963, 0.4664, 0.7586, 0.7212, 0.72, 0.7361]\n",
      "result: [0.4408, 0.4158, 0.8435, 0.7835, 0.7902, 0.8662, 0.8581, 0.8011, -1.0, 0.4281, 0.7655, 0.7512, 0.7518, 0.7801, 0.7968]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: cloudfixer, batch_size: 128, classifier: point2vec random_seed: 2\n",
      "unadapted_list: [0.459, 0.2018, 0.8588, 0.8197, 0.692, 0.5602, 0.4484, 0.5528, -1.0, 0.2979, 0.4734, 0.7515, 0.7146, 0.7252, 0.739]\n",
      "result: [0.4383, 0.4106, 0.8411, 0.7668, 0.7903, 0.879, 0.8761, 0.8917, -1.0, 0.6698, 0.7534, 0.757, 0.7507, 0.7762, 0.8025]\n",
      "\n",
      "corruption_list: ['occlusion', 'lidar', 'density_inc', 'density', 'cutout', 'uniform', 'gaussian', 'impulse', 'upsampling', 'background', 'rotation', 'shear', 'distortion', 'distortion_rbf', 'distortion_rbf_inv']\n",
      "method: cloudfixer, batch_size: 128, classifier: point2vec random_seed: 2\n",
      "unadapted_list: [0.4589, 0.2098, 0.8601, 0.8234, 0.6968, 0.5641, 0.4359, 0.5608, -1.0, 0.2973, 0.4668, 0.7568, 0.7171, 0.722, 0.7404]\n",
      "result: [0.436, 0.4061, 0.8387, 0.7709, 0.7834, 0.859, 0.8596, 0.8775, -1.0, 0.6778, 0.6682, 0.7509, 0.749, 0.7683, 0.7907]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class imbalance ratio (label distribution shift)\n",
    "\n",
    "# parse lame result\n",
    "classifier_list = [\"point2vec\"]\n",
    "METHOD_LIST = [\"cloudfixer\"]\n",
    "random_seed_list = [2]\n",
    "\n",
    "corruption_list = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]\n",
    "severity_list = [5]\n",
    "batch_size_list = [128]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_reg_method_uniform_false_false/run.log\"\n",
    "                        result = get_avg_online_recall(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_macro_recall']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_macro_recall']))\n",
    "            print(f\"corruption_list: {corruption_list}\")\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\")\n",
    "            print(f\"result: {result_list}\\n\")\n",
    "\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_reg_method_inv_dist_false_false/run.log\"\n",
    "                        result = get_avg_online_recall(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_macro_recall']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_macro_recall']))\n",
    "            print(f\"corruption_list: {corruption_list}\")\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\")\n",
    "            print(f\"result: {result_list}\\n\")\n",
    "\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_reg_method_curvature_based_false_false/run.log\"\n",
    "                        result = get_avg_online_recall(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_macro_recall']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_macro_recall']))\n",
    "            print(f\"corruption_list: {corruption_list}\")\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\")\n",
    "            print(f\"result: {result_list}\\n\")\n",
    "\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_reg_method_inv_dist_true_false/run.log\"\n",
    "                        result = get_avg_online_recall(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_macro_recall']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_macro_recall']))\n",
    "            print(f\"corruption_list: {corruption_list}\")\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\")\n",
    "            print(f\"result: {result_list}\\n\")\n",
    "\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for method in METHOD_LIST:\n",
    "        for classifier in classifier_list:\n",
    "            unadapted_result_list = []\n",
    "            result_list = []\n",
    "\n",
    "            for corruption in corruption_list:\n",
    "                for severity in severity_list: # one result\n",
    "                    for random_seed in random_seed_list:\n",
    "\n",
    "                        log_dir = f\"exps/eval_classifier_{classifier}_dataset_modelnet40c_{corruption}_{severity}_method_{method}_seed_{random_seed}_batch_size_{batch_size}_reg_method_inv_dist_false_true/run.log\"\n",
    "                        result = get_avg_online_recall(log_dir)\n",
    "                        result_list.append(float(result['after_adaptation_macro_recall']))\n",
    "                        unadapted_result_list.append(float(result['before_adaptation_macro_recall']))\n",
    "            print(f\"corruption_list: {corruption_list}\")\n",
    "            print(f\"method: {method}, batch_size: {batch_size}, classifier: {classifier} random_seed: {random_seed}\")\n",
    "            print(f\"unadapted_list: {unadapted_result_list}\")\n",
    "            print(f\"result: {result_list}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
